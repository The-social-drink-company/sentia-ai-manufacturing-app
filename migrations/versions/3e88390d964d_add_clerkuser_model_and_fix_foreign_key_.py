"""Add ClerkUser model and fix foreign key types to UUID

Revision ID: 3e88390d964d
Revises: 9b7af71df6ab
Create Date: 2025-09-02 15:56:59.702192

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '3e88390d964d'
down_revision = '9b7af71df6ab'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('api_credentials',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('provider', sa.Enum('SHOPIFY', 'AMAZON_SP', 'XERO', name='integrationprovider'), nullable=False),
    sa.Column('name', sa.String(length=100), nullable=False),
    sa.Column('client_id', sa.Text(), nullable=True),
    sa.Column('client_secret', sa.Text(), nullable=True),
    sa.Column('access_token', sa.Text(), nullable=True),
    sa.Column('refresh_token', sa.Text(), nullable=True),
    sa.Column('token_expires_at', sa.DateTime(), nullable=True),
    sa.Column('api_key', sa.Text(), nullable=True),
    sa.Column('shop_url', sa.String(length=255), nullable=True),
    sa.Column('marketplace_id', sa.String(length=50), nullable=True),
    sa.Column('region', sa.String(length=20), nullable=True),
    sa.Column('environment', sa.String(length=20), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('clerk_users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('clerk_user_id', sa.String(length=255), nullable=False),
    sa.Column('clerk_session_id', sa.String(length=255), nullable=True),
    sa.Column('email', sa.String(length=320), nullable=False),
    sa.Column('username', sa.String(length=64), nullable=True),
    sa.Column('first_name', sa.String(length=50), nullable=True),
    sa.Column('last_name', sa.String(length=50), nullable=True),
    sa.Column('role', sa.String(length=20), nullable=False),
    sa.Column('permissions', sa.JSON(), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=False),
    sa.Column('department', sa.String(length=50), nullable=True),
    sa.Column('access_regions', sa.JSON(), nullable=True),
    sa.Column('timezone', sa.String(length=50), nullable=True),
    sa.Column('language', sa.String(length=10), nullable=True),
    sa.Column('preferences', sa.JSON(), nullable=True),
    sa.Column('last_login', sa.DateTime(timezone=True), nullable=True),
    sa.Column('last_login_ip', sa.String(length=45), nullable=True),
    sa.Column('login_count', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('clerk_synced_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('clerk_data', sa.JSON(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('clerk_users', schema=None) as batch_op:
        batch_op.create_index('ix_clerk_user_email', ['email'], unique=False)
        batch_op.create_index('ix_clerk_user_last_login', ['last_login'], unique=False)
        batch_op.create_index('ix_clerk_user_role_active', ['role', 'is_active'], unique=False)
        batch_op.create_index(batch_op.f('ix_clerk_users_clerk_user_id'), ['clerk_user_id'], unique=True)
        batch_op.create_index(batch_op.f('ix_clerk_users_email'), ['email'], unique=False)
        batch_op.create_index(batch_op.f('ix_clerk_users_username'), ['username'], unique=False)

    op.create_table('system_metrics',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('metric_name', sa.String(length=100), nullable=False),
    sa.Column('metric_value', sa.Float(), nullable=False),
    sa.Column('unit', sa.String(length=20), nullable=True),
    sa.Column('recorded_at', sa.DateTime(), nullable=True),
    sa.Column('source', sa.String(length=50), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('system_metrics', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_system_metrics_recorded_at'), ['recorded_at'], unique=False)

    op.create_table('webhook_events',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('provider', sa.Enum('SHOPIFY', 'AMAZON_SP', 'XERO', name='integrationprovider'), nullable=False),
    sa.Column('event_type', sa.String(length=100), nullable=False),
    sa.Column('event_id', sa.String(length=255), nullable=True),
    sa.Column('topic', sa.String(length=100), nullable=True),
    sa.Column('payload', sa.JSON(), nullable=False),
    sa.Column('headers', sa.JSON(), nullable=True),
    sa.Column('processed', sa.Boolean(), nullable=True),
    sa.Column('processed_at', sa.DateTime(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('retry_count', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('api_integrations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('credential_id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(length=100), nullable=False),
    sa.Column('provider', sa.Enum('SHOPIFY', 'AMAZON_SP', 'XERO', name='integrationprovider'), nullable=False),
    sa.Column('integration_type', sa.Enum('API', 'WEBHOOK', 'BATCH', name='integrationtype'), nullable=False),
    sa.Column('endpoint_url', sa.String(length=500), nullable=True),
    sa.Column('webhook_url', sa.String(length=500), nullable=True),
    sa.Column('sync_frequency_minutes', sa.Integer(), nullable=True),
    sa.Column('last_sync_at', sa.DateTime(), nullable=True),
    sa.Column('next_sync_at', sa.DateTime(), nullable=True),
    sa.Column('status', sa.Enum('ACTIVE', 'INACTIVE', 'ERROR', 'RATE_LIMITED', 'AUTHENTICATING', name='integrationstatus'), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('retry_count', sa.Integer(), nullable=True),
    sa.Column('max_retries', sa.Integer(), nullable=True),
    sa.Column('rate_limit_remaining', sa.Integer(), nullable=True),
    sa.Column('rate_limit_reset_at', sa.DateTime(), nullable=True),
    sa.Column('config_json', sa.JSON(), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['credential_id'], ['api_credentials.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('backup_records',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('backup_type', sa.String(length=20), nullable=False),
    sa.Column('file_path', sa.String(length=500), nullable=True),
    sa.Column('file_size_mb', sa.Float(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('duration_seconds', sa.Integer(), nullable=True),
    sa.Column('created_by_id', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['created_by_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('data_imports',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('import_name', sa.String(length=200), nullable=False),
    sa.Column('import_type', sa.Enum('PRODUCTS', 'HISTORICAL_SALES', 'INVENTORY_LEVELS', 'MANUFACTURING_DATA', 'FINANCIAL_DATA', 'FORECASTS', name='importtype'), nullable=False),
    sa.Column('import_description', sa.Text(), nullable=True),
    sa.Column('original_filename', sa.String(length=255), nullable=True),
    sa.Column('file_type', sa.Enum('CSV', 'XLSX', 'JSON', 'XML', 'API', name='filetype'), nullable=False),
    sa.Column('file_path', sa.String(length=500), nullable=True),
    sa.Column('file_size_bytes', sa.BigInteger(), nullable=True),
    sa.Column('file_hash', sa.String(length=64), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'PROCESSING', 'VALIDATING', 'COMPLETED', 'FAILED', 'CANCELLED', name='importstatus'), nullable=False),
    sa.Column('progress_percentage', sa.Integer(), nullable=True),
    sa.Column('current_step', sa.String(length=100), nullable=True),
    sa.Column('total_rows', sa.Integer(), nullable=True),
    sa.Column('processed_rows', sa.Integer(), nullable=True),
    sa.Column('successful_rows', sa.Integer(), nullable=True),
    sa.Column('failed_rows', sa.Integer(), nullable=True),
    sa.Column('duplicate_rows', sa.Integer(), nullable=True),
    sa.Column('data_quality_score', sa.Numeric(precision=3, scale=2), nullable=True),
    sa.Column('completeness_score', sa.Numeric(precision=3, scale=2), nullable=True),
    sa.Column('accuracy_score', sa.Numeric(precision=3, scale=2), nullable=True),
    sa.Column('import_settings', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('validation_rules', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('field_mappings', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('processing_duration_seconds', sa.Integer(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('error_details', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('rollback_completed', sa.Boolean(), nullable=True),
    sa.Column('created_by', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('data_imports', schema=None) as batch_op:
        batch_op.create_index('ix_data_imports_created_user', ['created_at', 'created_by'], unique=False)
        batch_op.create_index(batch_op.f('ix_data_imports_import_type'), ['import_type'], unique=False)
        batch_op.create_index('ix_data_imports_processing', ['status', 'started_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_data_imports_status'), ['status'], unique=False)
        batch_op.create_index('ix_data_imports_status_type', ['status', 'import_type'], unique=False)

    op.create_table('import_templates',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('template_name', sa.String(length=100), nullable=False),
    sa.Column('import_type', sa.Enum('PRODUCTS', 'HISTORICAL_SALES', 'INVENTORY_LEVELS', 'MANUFACTURING_DATA', 'FINANCIAL_DATA', 'FORECASTS', name='importtype'), nullable=False),
    sa.Column('version', sa.String(length=20), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('file_format', sa.Enum('CSV', 'XLSX', 'JSON', 'XML', 'API', name='filetype'), nullable=False),
    sa.Column('field_definitions', postgresql.JSON(astext_type=sa.Text()), nullable=False),
    sa.Column('sample_data', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('validation_rules', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('template_file_path', sa.String(length=500), nullable=True),
    sa.Column('documentation_path', sa.String(length=500), nullable=True),
    sa.Column('download_count', sa.Integer(), nullable=True),
    sa.Column('usage_count', sa.Integer(), nullable=True),
    sa.Column('success_rate', sa.Numeric(precision=5, scale=2), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('is_system_template', sa.Boolean(), nullable=True),
    sa.Column('created_by', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('template_name')
    )
    with op.batch_alter_table('import_templates', schema=None) as batch_op:
        batch_op.create_index('ix_import_templates_type_active', ['import_type', 'is_active'], unique=False)
        batch_op.create_index('ix_import_templates_usage', ['usage_count', 'success_rate'], unique=False)

    op.create_table('maintenance_windows',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(length=200), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('scheduled_start', sa.DateTime(), nullable=False),
    sa.Column('scheduled_end', sa.DateTime(), nullable=False),
    sa.Column('actual_start', sa.DateTime(), nullable=True),
    sa.Column('actual_end', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('maintenance_mode_enabled', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('created_by_id', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['created_by_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('security_events',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('event_type', sa.String(length=50), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('ip_address', sa.String(length=45), nullable=True),
    sa.Column('user_agent', sa.Text(), nullable=True),
    sa.Column('risk_level', sa.Integer(), nullable=True),
    sa.Column('blocked', sa.Boolean(), nullable=True),
    sa.Column('occurred_at', sa.DateTime(), nullable=True),
    sa.Column('user_id', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('security_events', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_security_events_occurred_at'), ['occurred_at'], unique=False)

    op.create_table('system_alerts',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(length=200), nullable=False),
    sa.Column('message', sa.Text(), nullable=False),
    sa.Column('alert_type', sa.Enum('INFO', 'WARNING', 'ERROR', 'SUCCESS', name='alerttype'), nullable=False),
    sa.Column('status', sa.Enum('UNREAD', 'READ', 'DISMISSED', name='alertstatus'), nullable=True),
    sa.Column('source', sa.String(length=100), nullable=True),
    sa.Column('severity', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('read_at', sa.DateTime(), nullable=True),
    sa.Column('dismissed_at', sa.DateTime(), nullable=True),
    sa.Column('created_by_id', sa.UUID(), nullable=True),
    sa.ForeignKeyConstraint(['created_by_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('import_errors',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('import_id', sa.UUID(), nullable=False),
    sa.Column('row_number', sa.Integer(), nullable=True),
    sa.Column('column_name', sa.String(length=100), nullable=True),
    sa.Column('error_type', sa.String(length=50), nullable=False),
    sa.Column('error_code', sa.String(length=20), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=False),
    sa.Column('error_severity', sa.String(length=20), nullable=True),
    sa.Column('original_value', sa.Text(), nullable=True),
    sa.Column('suggested_value', sa.Text(), nullable=True),
    sa.Column('row_data', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('is_resolved', sa.Boolean(), nullable=True),
    sa.Column('resolution_method', sa.String(length=50), nullable=True),
    sa.Column('resolved_by', sa.UUID(), nullable=True),
    sa.Column('resolved_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('resolution_notes', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['import_id'], ['data_imports.id'], ),
    sa.ForeignKeyConstraint(['resolved_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('import_errors', schema=None) as batch_op:
        batch_op.create_index('ix_import_errors_import_severity', ['import_id', 'error_severity'], unique=False)
        batch_op.create_index('ix_import_errors_row', ['import_id', 'row_number'], unique=False)
        batch_op.create_index('ix_import_errors_type_resolved', ['error_type', 'is_resolved'], unique=False)

    op.create_table('import_logs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('import_id', sa.UUID(), nullable=False),
    sa.Column('log_level', sa.String(length=20), nullable=False),
    sa.Column('log_message', sa.Text(), nullable=False),
    sa.Column('log_context', postgresql.JSON(astext_type=sa.Text()), nullable=True),
    sa.Column('step_name', sa.String(length=100), nullable=True),
    sa.Column('row_number', sa.Integer(), nullable=True),
    sa.Column('processing_time_ms', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['import_id'], ['data_imports.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('import_logs', schema=None) as batch_op:
        batch_op.create_index('ix_import_logs_created', ['created_at'], unique=False)
        batch_op.create_index('ix_import_logs_import_level', ['import_id', 'log_level'], unique=False)

    op.create_table('integration_health',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('integration_id', sa.Integer(), nullable=False),
    sa.Column('check_time', sa.DateTime(), nullable=True),
    sa.Column('is_healthy', sa.Boolean(), nullable=False),
    sa.Column('response_time_ms', sa.Integer(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('status_code', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['integration_id'], ['api_integrations.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('integration_sync_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('integration_id', sa.Integer(), nullable=False),
    sa.Column('sync_type', sa.String(length=50), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('records_processed', sa.Integer(), nullable=True),
    sa.Column('records_success', sa.Integer(), nullable=True),
    sa.Column('records_failed', sa.Integer(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('response_data', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['integration_id'], ['api_integrations.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('integration_sync_logs')
    op.drop_table('integration_health')
    with op.batch_alter_table('import_logs', schema=None) as batch_op:
        batch_op.drop_index('ix_import_logs_import_level')
        batch_op.drop_index('ix_import_logs_created')

    op.drop_table('import_logs')
    with op.batch_alter_table('import_errors', schema=None) as batch_op:
        batch_op.drop_index('ix_import_errors_type_resolved')
        batch_op.drop_index('ix_import_errors_row')
        batch_op.drop_index('ix_import_errors_import_severity')

    op.drop_table('import_errors')
    op.drop_table('system_alerts')
    with op.batch_alter_table('security_events', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_security_events_occurred_at'))

    op.drop_table('security_events')
    op.drop_table('maintenance_windows')
    with op.batch_alter_table('import_templates', schema=None) as batch_op:
        batch_op.drop_index('ix_import_templates_usage')
        batch_op.drop_index('ix_import_templates_type_active')

    op.drop_table('import_templates')
    with op.batch_alter_table('data_imports', schema=None) as batch_op:
        batch_op.drop_index('ix_data_imports_status_type')
        batch_op.drop_index(batch_op.f('ix_data_imports_status'))
        batch_op.drop_index('ix_data_imports_processing')
        batch_op.drop_index(batch_op.f('ix_data_imports_import_type'))
        batch_op.drop_index('ix_data_imports_created_user')

    op.drop_table('data_imports')
    op.drop_table('backup_records')
    op.drop_table('api_integrations')
    op.drop_table('webhook_events')
    with op.batch_alter_table('system_metrics', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_system_metrics_recorded_at'))

    op.drop_table('system_metrics')
    with op.batch_alter_table('clerk_users', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_clerk_users_username'))
        batch_op.drop_index(batch_op.f('ix_clerk_users_email'))
        batch_op.drop_index(batch_op.f('ix_clerk_users_clerk_user_id'))
        batch_op.drop_index('ix_clerk_user_role_active')
        batch_op.drop_index('ix_clerk_user_last_login')
        batch_op.drop_index('ix_clerk_user_email')

    op.drop_table('clerk_users')
    op.drop_table('api_credentials')
    # ### end Alembic commands ###
