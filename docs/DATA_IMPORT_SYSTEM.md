# Data Import System Documentation\n\n## Overview\n\nThe CapLiquify Manufacturing Platform includes a comprehensive data import system that allows users to upload, validate, and import various types of manufacturing and business data into the system. The system is designed to handle large datasets while ensuring data quality and consistency.\n\n## System Architecture\n\n### Frontend Components\n\n#### DataImportDashboard\nMain dashboard component that orchestrates the entire import process.\n- **Location**: `src/components/DataImport/DataImportDashboard.jsx`\n- **Features**: Step management, import history, queue monitoring\n- **Dependencies**: All other DataImport components\n\n#### DataImportUploader  \nHandles file selection and upload with drag-and-drop support.\n- **Location**: `src/components/DataImport/DataImportUploader.jsx`\n- **Features**: File validation, progress tracking, error handling\n- **Supported Formats**: CSV, XLSX, JSON (up to 10MB)\n\n#### DataImportStepper\nVisual progress indicator showing current step in the import process.\n- **Location**: `src/components/DataImport/DataImportStepper.jsx`\n- **Steps**: Upload → Preview & Map → Validate → Process → Results\n\n#### DataPreviewMapper\nAllows users to preview uploaded data and map source columns to target fields.\n- **Location**: `src/components/DataImport/DataPreviewMapper.jsx`\n- **Features**: Auto-mapping, field validation, export mapping config\n\n#### ValidationConfig\nConfiguration interface for validation rules and business logic.\n- **Location**: `src/components/DataImport/ValidationConfig.jsx`\n- **Features**: Rule configuration, custom rules, validation preview\n\n#### DataImportResults\nDisplays import results with detailed error reporting and statistics.\n- **Location**: `src/components/DataImport/DataImportResults.jsx`\n- **Features**: Error analysis, data quality metrics, export reports\n\n#### ImportTemplateManager\nManages import templates and specifications for different data types.\n- **Location**: `src/components/DataImport/ImportTemplateManager.jsx`\n- **Features**: Template download, specification export, usage statistics\n\n### Backend Services\n\n#### Queue Service\nHandles background processing using BullMQ and Redis.\n- **Location**: `src/services/queueService.js`\n- **Features**: Job queuing, progress tracking, error handling\n- **Queues**: data-import, data-validation\n\n#### Validation Engine\nComprehensive data validation based on business rules.\n- **Location**: `src/services/validationEngine.js`\n- **Features**: Type validation, business rules, error reporting\n- **Validation Types**: Format, range, business logic, cross-field\n\n#### Database Service\nHandles database connections and operations.\n- **Location**: `src/services/db/index.js`\n- **Features**: Connection pooling, transactions, health checks\n\n### API Endpoints\n\n#### File Upload\n- **POST** `/api/import/upload`\n- **Purpose**: Upload and initially process files\n- **Body**: Multipart form data with file and metadata\n- **Response**: Import job ID and file details\n\n#### File Preview\n- **GET** `/api/import/preview/:importJobId`\n- **Purpose**: Get preview of uploaded data\n- **Response**: Headers, sample rows, file metadata\n\n#### Start Processing\n- **POST** `/api/import/process/:importJobId`\n- **Purpose**: Start file processing with mapping configuration\n- **Body**: Mapping config and validation rules\n- **Response**: Queue job ID\n\n#### Start Validation\n- **POST** `/api/import/validate/:importJobId`\n- **Purpose**: Start validation process\n- **Body**: Validation configuration\n- **Response**: Queue job ID\n\n#### Validation Preview\n- **POST** `/api/import/validate-preview`\n- **Purpose**: Run validation on sample data\n- **Body**: Validation rules and sample size\n- **Response**: Preview validation results\n\n#### Import Status\n- **GET** `/api/import/status/:importJobId`\n- **Purpose**: Get current status of import job\n- **Response**: Job status, progress, row counts\n\n#### Import Results\n- **GET** `/api/import/results/:importJobId`\n- **Purpose**: Get detailed validation results\n- **Response**: Error details, warnings, processed data\n\n#### Import History\n- **GET** `/api/import/jobs`\n- **Purpose**: Get list of import jobs with pagination\n- **Query Params**: page, pageSize\n- **Response**: Job list with metadata\n\n#### Queue Statistics\n- **GET** `/api/queue/stats`\n- **Purpose**: Get queue health and statistics\n- **Response**: Queue status, job counts\n\n## Data Types Supported\n\n### Products\n- **SKU**: Unique product identifier (required)\n- **Name**: Product name (required)\n- **Weight**: Weight in kg (required)\n- **Dimensions**: LxWxH in cm (required)\n- **Costs**: Unit cost and selling price\n- **Production**: Time and batch size information\n\n### Historical Sales\n- **SKU**: Product identifier (required)\n- **Sale Date**: Transaction date (required)\n- **Quantity**: Units sold (required)\n- **Price**: Unit price and currency (required)\n- **Location**: Shipping country and sales channel\n- **Revenue**: Gross, net, discounts\n\n### Inventory Levels\n- **SKU**: Product identifier (required)\n- **Location**: Warehouse location (required)\n- **Quantities**: On hand, reserved, available\n- **Thresholds**: Reorder point, max stock level\n- **Timestamps**: Last updated information\n\n### Manufacturing Data\n- **Job Number**: Unique job identifier (required)\n- **Product SKU**: Product being manufactured (required)\n- **Batch**: Batch number and production date (required)\n- **Quality**: Quality scores, defect rates, yield\n- **Costs**: Production costs and efficiency metrics\n\n### Financial Data\n- **Date**: Transaction date (required)\n- **Type**: Transaction type (required)\n- **Amount**: Transaction amount and currency (required)\n- **References**: Account codes, descriptions\n\n## Validation Rules\n\n### Field-Level Validation\n- **Type Validation**: String, number, integer, date, boolean\n- **Format Validation**: Regex patterns, date formats\n- **Range Validation**: Min/max values for numbers\n- **Length Validation**: Min/max length for strings\n- **Enum Validation**: Allowed values from predefined lists\n\n### Business Rules Validation\n- **Cross-Field Rules**: selling_price > unit_cost\n- **Calculation Rules**: gross_revenue = quantity × unit_price\n- **Reference Integrity**: SKU must exist in products\n- **Date Logic**: Sale date cannot be in future\n- **Inventory Rules**: Available = On hand - Reserved\n\n### Data Quality Scoring\n- **Completeness Score**: Based on required vs optional fields\n- **Accuracy Score**: Based on validation rule compliance\n- **Quality Bands**: Excellent (90-100%), Good (75-89%), Acceptable (60-74%), Poor (<60%)\n\n## Queue Processing\n\n### Architecture\n- **Message Broker**: Redis\n- **Queue Library**: BullMQ\n- **Concurrency**: 2 import workers, 3 validation workers\n- **Retry Logic**: Exponential backoff with configurable attempts\n\n### Job Types\n1. **Import Jobs**: File parsing and data extraction\n2. **Validation Jobs**: Data validation and quality checking\n\n### Job States\n- **Uploaded**: File uploaded, awaiting processing\n- **Processing**: File being parsed and mapped\n- **Validation Pending**: Awaiting validation processing\n- **Validating**: Validation rules being applied\n- **Completed**: Successfully processed\n- **Completed with Errors**: Processed but has validation errors\n- **Failed**: Processing failed\n\n### Fallback Behavior\nIf Redis/queue service is unavailable, the system falls back to synchronous processing to maintain functionality.\n\n## Database Schema\n\n### import_job Table\n- **id**: Primary key\n- **filename**: Original filename\n- **file_path**: Server file path\n- **file_size**: Size in bytes\n- **file_type**: MIME type\n- **data_type**: Target data type\n- **status**: Current processing status\n- **mapping_config**: Field mapping JSON\n- **validation_rules**: Validation config JSON\n- **total_rows**: Total rows in file\n- **processed_rows**: Successfully processed rows\n- **error_rows**: Rows with errors\n- **warnings**: Warning messages JSON\n- **uploaded_by**: User ID\n- **timestamps**: Upload, process, completion times\n\n### validation_result Table\n- **id**: Primary key\n- **import_job_id**: Foreign key to import_job\n- **row_number**: Row number in original file\n- **status**: Validation status (valid/error/warning)\n- **errors**: Error details JSON\n- **warnings**: Warning details JSON\n- **original_data**: Original row data JSON\n- **processed_data**: Processed row data JSON\n- **created_at**: Validation timestamp\n\n## Error Handling\n\n### Error Classification\n- **Critical Errors**: Stop import (type mismatches, missing required fields)\n- **Warning Errors**: Allow import with flags (quality concerns, outliers)\n- **Info Messages**: Informational only (transformations applied)\n\n### Error Resolution\n1. **Detection**: Real-time during validation\n2. **Logging**: Detailed error messages with context\n3. **Notification**: User alerts with correction guidance\n4. **Correction**: Web interface for manual fixes\n5. **Revalidation**: Automatic after corrections\n\n## Security Considerations\n\n### File Upload Security\n- **File Type Validation**: Only allow approved MIME types\n- **Size Limits**: 10MB maximum file size\n- **Virus Scanning**: Recommended for production\n- **Path Sanitization**: Prevent directory traversal\n\n### Data Security\n- **Access Control**: Role-based permissions\n- **Audit Trail**: All operations logged\n- **Data Encryption**: At rest and in transit\n- **Cleanup**: Temporary files removed after processing\n\n## Performance Optimization\n\n### File Processing\n- **Streaming**: Large file processing without full memory load\n- **Batch Processing**: Validate in configurable batch sizes\n- **Parallel Processing**: Concurrent validation where possible\n- **Caching**: Validation rule caching\n\n### Database Optimization\n- **Indexing**: Proper indexes on frequently queried fields\n- **Connection Pooling**: Efficient database connections\n- **Batch Operations**: Bulk inserts for better performance\n\n## Monitoring and Logging\n\n### Metrics Tracked\n- **Import Volume**: Files and rows processed\n- **Success Rates**: Completion vs failure rates\n- **Processing Times**: Average processing duration\n- **Error Rates**: Common error types and frequencies\n- **Queue Health**: Queue depth and processing rates\n\n### Logging\n- **Structured Logging**: JSON format with Winston\n- **Log Levels**: Error, warn, info, debug\n- **Log Rotation**: Daily rotation with retention\n- **Error Tracking**: Detailed stack traces for failures\n\n## Deployment Considerations\n\n### Environment Variables\n```bash\n# Redis Configuration (for queues)\nREDIS_HOST=localhost\nREDIS_PORT=6379\nREDIS_PASSWORD=\nREDIS_DB=0\n\n# File Upload Configuration\nUPLOAD_FOLDER=uploads\nMAX_CONTENT_LENGTH=16777216  # 16MB\n\n# Queue Configuration\nQUEUE_CONCURRENCY_IMPORT=2\nQUEUE_CONCURRENCY_VALIDATION=3\n```\n\n### Production Setup\n1. **Redis Setup**: Configure Redis for queue processing\n2. **File Storage**: Ensure sufficient disk space for uploads\n3. **Monitoring**: Set up alerts for queue health and error rates\n4. **Backup**: Regular backup of import job metadata\n\n## Usage Examples\n\n### Basic Import Workflow\n```javascript\n// 1. Upload file\nconst formData = new FormData();\nformData.append('file', file);\nformData.append('dataType', 'products');\nconst uploadResponse = await fetch('/api/import/upload', {\n  method: 'POST',\n  body: formData\n});\n\n// 2. Preview and map fields\nconst preview = await fetch(`/api/import/preview/${importJobId}`);\nconst mapping = { sku: 'Product Code', name: 'Product Name' };\n\n// 3. Start processing\nconst processResponse = await fetch(`/api/import/process/${importJobId}`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({ mappingConfig: mapping })\n});\n\n// 4. Start validation\nconst validateResponse = await fetch(`/api/import/validate/${importJobId}`, {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({ validationConfig: rules })\n});\n\n// 5. Check results\nconst results = await fetch(`/api/import/results/${importJobId}`);\n```\n\n### Custom Validation Rule\n```javascript\nconst customRule = {\n  name: 'Profit Margin Check',\n  description: 'Ensure minimum 10% profit margin',\n  expression: '(selling_price - unit_cost) / unit_cost >= 0.1',\n  severity: 'warning',\n  enabled: true\n};\n```\n\n## Troubleshooting\n\n### Common Issues\n\n#### Upload Failures\n- **File too large**: Check file size limits\n- **Invalid file type**: Verify supported formats\n- **Network timeout**: Check file size and connection\n\n#### Processing Failures\n- **Queue unavailable**: Check Redis connection\n- **Memory issues**: Reduce batch size\n- **Database timeout**: Check database performance\n\n#### Validation Errors\n- **Type mismatches**: Review data types in template\n- **Business rule failures**: Check business logic\n- **Missing references**: Ensure related data exists\n\n### Debug Information\n- **Queue Stats**: Use `/api/queue/stats` to check queue health\n- **Import Status**: Monitor progress with `/api/import/status/:id`\n- **Logs**: Check Winston logs for detailed error information\n\n## Future Enhancements\n\n### Planned Features\n- **Real-time Collaboration**: Multiple users working on same import\n- **Advanced Scheduling**: Scheduled imports and updates\n- **Data Transformation**: Built-in data transformation rules\n- **Integration APIs**: Direct integration with external systems\n- **Machine Learning**: Intelligent field mapping suggestions\n- **Audit Reports**: Comprehensive audit and compliance reporting\n\n### Performance Improvements\n- **Distributed Processing**: Multi-server processing\n- **Incremental Updates**: Support for incremental data updates\n- **Caching Layer**: Redis caching for validation rules\n- **Async Notifications**: WebSocket notifications for real-time updates"